{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7ce8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f8a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_df = pd.read_csv(\"mistral_data.csv\")  # 0-AI, 1-HUMAN\n",
    "persuade_df = pd.read_csv(\"persuade.csv\")  # ALL HUMAN\n",
    "gpt_df = pd.read_csv(\"chat_gpt_essay.csv\")  # ALL AI\n",
    "comp_df = pd.read_csv(\"train_essays_comp.csv\")  # 1-AI, 0-HUMAN\n",
    "daigt_df = pd.read_csv(\"daigt_train.csv\")  # 1-AI, 0-HUMAN\n",
    "\n",
    "human_text_mistral = mistral_df.query('LABEL == 1')['Text']\n",
    "human_text_persuade = persuade_df['full_text'].sample(frac=1)\n",
    "human_text_comp = comp_df.query('generated == 0')['text']\n",
    "human_text_daigt = daigt_df.query('label == 0')['text']\n",
    "\n",
    "ai_text_mistral = mistral_df.query('LABEL == 0')['Text']\n",
    "ai_text_gpt = gpt_df['Text']\n",
    "ai_text_comp = comp_df.query('generated == 1')['text']\n",
    "ai_text_daigt = daigt_df.query('label == 1')['text']\n",
    "\n",
    "human_texts = pd.concat([human_text_mistral, human_text_comp, human_text_daigt], ignore_index=True)\n",
    "ai_texts = pd.concat([ai_text_mistral, ai_text_gpt, ai_text_comp, ai_text_daigt], ignore_index=True)\n",
    "\n",
    "df_human = pd.DataFrame(human_texts, columns=['text'])\n",
    "df_human['generated'] = 0 \n",
    "\n",
    "df_ai = pd.DataFrame(ai_texts, columns=['text'])\n",
    "df_ai['generated'] = 1  \n",
    "\n",
    "df_human = df_human.iloc[:20000] #only 20k\n",
    "df_ai = df_ai.iloc[:20000]\n",
    "\n",
    "df_final = pd.DataFrame(columns = ['text', 'generated'])\n",
    "df_final = pd.concat([df_human, df_ai, df_final])\n",
    "df_final = df_final.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d830c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>Dear [Principal’s Name],\\n\\nI am writing this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12531</th>\n",
       "      <td>\"Making Mona Lisa Smile\" is about a computer h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>The author supports the idea that studying Ven...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>In my opinion, it is not a good idea to gradu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18939</th>\n",
       "      <td>Driverless cars will be available in the futur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>Do you ever want to do something fun at your s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17063</th>\n",
       "      <td>The sky was a clear blue, and the sun was shin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>In this article it talks about the face of Mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>Hey there!  So, you wanna know about the benef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to express my su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text generated\n",
       "4907   Dear [Principal’s Name],\\n\\nI am writing this ...         1\n",
       "12531  \"Making Mona Lisa Smile\" is about a computer h...         0\n",
       "11359  The author supports the idea that studying Ven...         0\n",
       "6070    In my opinion, it is not a good idea to gradu...         1\n",
       "18939  Driverless cars will be available in the futur...         0\n",
       "...                                                  ...       ...\n",
       "8761   Do you ever want to do something fun at your s...         0\n",
       "17063  The sky was a clear blue, and the sun was shin...         1\n",
       "12108  In this article it talks about the face of Mon...         0\n",
       "3673   Hey there!  So, you wanna know about the benef...         1\n",
       "1468   Dear Senator,\\n\\nI am writing to express my su...         1\n",
       "\n",
       "[39300 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcaa6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def build_vocab(texts):\n",
    "    for text in texts:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab_df = Vocab(build_vocab_from_iterator(build_vocab(df_final['text']), max_tokens = 20000, min_freq = 1, specials=('<unk>', '<pad>')))\n",
    "vocab_df.set_default_index(vocab_df['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5448ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3819\n",
      "24\n",
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer(\"Hello this is Mridul\"):\n",
    "    print(vocab_df[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac621c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "glove = vocab.GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5304b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16640 words out of 20000 total\n"
     ]
    }
   ],
   "source": [
    "def get_glove_embedding(vocab_df, glove):\n",
    "    emb_dim = glove.dim\n",
    "    embedding = torch.zeros(vocab_df.__len__(), emb_dim)\n",
    "    num_loaded = 0\n",
    "    \n",
    "    for i, token in enumerate(vocab_df.get_itos()):\n",
    "        if token in glove.stoi:\n",
    "            embedding[i] = glove[token]\n",
    "            num_loaded += 1\n",
    "        else:\n",
    "            embedding[i] = 0 #torch.randn(emb_dim)\n",
    "    \n",
    "    print(f\"Loaded {num_loaded} words out of {len(vocab_df)} total\")\n",
    "    return embedding\n",
    "\n",
    "embedding_weight = get_glove_embedding(vocab_df, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab280236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39300it [00:32, 1204.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def text_to_tensor(texts, vocab_df, max_len=200):\n",
    "    tensor = torch.ones((len(texts), max_len), dtype=torch.long)\n",
    "    \n",
    "    for i, text in tqdm(enumerate(texts)):\n",
    "        tokenized_text = tokenizer(text)\n",
    "        for j, token in enumerate(tokenized_text):\n",
    "            if j >= max_len:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                tensor[i, j] = vocab_df.__getitem__(token)\n",
    "            except:\n",
    "                tensor[i, j] = 0\n",
    "            #tensor[i, j] = vocab_df.get_stoi().get(token, vocab_df['<unk>'])\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "text_tensors = text_to_tensor(df_final['text'], vocab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55c1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_final['generated'], dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf60763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "train_sent = text_tensors[:38000]\n",
    "train_labels = labels[:38000]\n",
    "test_sent = text_tensors[38000:]\n",
    "test_labels = labels[38000:]\n",
    "    \n",
    "train_dataset = TextDataset(train_sent, train_labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TextDataset(test_sent, test_labels)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2be64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IdentifyText(nn.Module):\n",
    "    def __init__(self, embedding_weights, \n",
    "                 hidden_dim, output_dim=2, \n",
    "                 num_layers=2, dropout=0.2):\n",
    "        super(IdentifyText, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        \n",
    "        # Ensuring dropout is only applied if there are multiple LSTM layers\n",
    "        effective_dropout = dropout if num_layers > 1 else 0\n",
    "        self.lstm = nn.LSTM(embedding_weights.shape[1], hidden_dim, \n",
    "                            num_layers=num_layers, batch_first=True, \n",
    "                            dropout=effective_dropout)\n",
    "        \n",
    "        self.fully_connected_1 = nn.Linear(hidden_dim, 64)\n",
    "        self.fully_connected_2 = nn.Linear(64, 64)\n",
    "        self.fully_connected_3 = nn.Linear(64, 32)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)    \n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.out = nn.Linear(32, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)  # [batch size, sent_length]\n",
    "            \n",
    "        output_lstm, (hidden_lstm, cell) = self.lstm(embedded)\n",
    "        \n",
    "        hidden_1 = torch.relu(self.fully_connected_1(hidden_lstm[-1]))\n",
    "        hidden_2 = torch.relu(self.fully_connected_2(hidden_1))\n",
    "        hidden_3 = torch.relu(self.fully_connected_3(hidden_2))\n",
    "        \n",
    "        output = self.softmax(self.out(hidden_3))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1e8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "output_dim = 2  \n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "model = IdentifyText(embedding_weight, hidden_dim, output_dim, num_layers, dropout)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for texts, labels in train_loader:\n",
    "#             texts = texts.to(device) \n",
    "#             labels = labels.to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db7671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6720302944582721\n",
      "Epoch 2, Loss: 0.5082429432206683\n",
      "Epoch 3, Loss: 0.7543646959644376\n",
      "Epoch 4, Loss: 0.8229418499802901\n",
      "Epoch 5, Loss: 0.8229155460190692\n",
      "Epoch 6, Loss: 0.8228629353873256\n",
      "Epoch 7, Loss: 0.756515675973812\n",
      "Epoch 8, Loss: 0.42742429415284583\n",
      "Epoch 9, Loss: 0.3816421390934424\n",
      "Epoch 10, Loss: 0.37804312374355015\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, optimizer, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "978afc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 300.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[207, 181,  75,  84,  12,  26,  93,   2,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_sent = \"Using phone while driving is not good.\"\n",
    "encoded_test = text_to_tensor([test_sent], vocab_df)\n",
    "\n",
    "print(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8620f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, pred = torch.max(model(encoded_test).data, 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf00de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 94.62%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.61538461538461"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for texts, labels in test_loader:\n",
    "            texts = texts\n",
    "            labels = labels\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test data: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935d4cf",
   "metadata": {},
   "source": [
    "# Paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "335df1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:00, 646.22it/s]\n"
     ]
    }
   ],
   "source": [
    "para_data = pd.read_csv(\"parahrased_human.csv\")\n",
    "para_human = np.array(para_data['Paraphrased']) #output should be AI gen\n",
    "\n",
    "revised_para_human = []\n",
    "for string in para_human:\n",
    "    if type(string) != float:\n",
    "        revised_para_human.append(string)\n",
    "\n",
    "revised_para_human = np.array(revised_para_human)\n",
    "para_tensors = text_to_tensor(revised_para_human, vocab_df)\n",
    "\n",
    "para_label = np.ones(97)\n",
    "\n",
    "para_dataset = TextDataset(para_tensors, para_label)\n",
    "para_loader = DataLoader(dataset=para_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d4a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 96.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.90721649484536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def para_model(model):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for texts, labels in para_loader:\n",
    "            texts = texts\n",
    "            labels = labels\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test data: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "para_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b9996",
   "metadata": {},
   "source": [
    "# CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9e4b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [00:01, 1234.51it/s]\n"
     ]
    }
   ],
   "source": [
    "para_gpt = pd.read_csv(\"GPTparaphrased.csv\")\n",
    "para_gpt_text = np.array(para_gpt['paraphrased'])\n",
    "\n",
    "para_gpt_label = np.ones(para_gpt['LABEL'])\n",
    "\n",
    "para_gpt_tensors = text_to_tensor(para_gpt_text, vocab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6148807",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dataset_gpt = TextDataset(para_gpt_tensors, para_gpt_label)\n",
    "para_loader_gpt = DataLoader(dataset=para_dataset_gpt, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d38a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 99.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.46666666666667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def para_model_gpt(model):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for texts, labels in para_loader_gpt:\n",
    "            texts = texts\n",
    "            labels = labels\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test data: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "para_model_gpt(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d4dc",
   "metadata": {},
   "source": [
    "# Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "269b24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497\n"
     ]
    }
   ],
   "source": [
    "para_human_gpt = pd.read_csv(\"GPT4_HumanParaphrase.csv\")\n",
    "para_human_gpt_text = para_human_gpt['Text']\n",
    "\n",
    "revised_para_gpt_human = []\n",
    "for string in para_human_gpt_text:\n",
    "    if type(string) != float:\n",
    "        revised_para_gpt_human.append(string)\n",
    "        \n",
    "print(len(revised_para_gpt_human))\n",
    "\n",
    "\n",
    "para_human_gpt_label = np.ones(len(revised_para_gpt_human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1926c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1497it [00:01, 1286.59it/s]\n"
     ]
    }
   ],
   "source": [
    "para_human_gpt_tensors = text_to_tensor(revised_para_gpt_human, vocab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d5ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dataset_gpt_human = TextDataset(para_human_gpt_tensors, para_human_gpt_label)\n",
    "para_loader_gpt_human = DataLoader(dataset=para_dataset_gpt_human, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa35487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0aca42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 0.90\n",
      "F1 Score: 0.95\n",
      "Accuracy of the model on the test data: 90.38%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.38076152304609"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def para_model_gpt_human(model):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for texts, labels in para_loader_gpt_human:\n",
    "            texts = texts\n",
    "            labels = labels\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted)\n",
    "            all_labels.extend(labels)\n",
    "            \n",
    "    precision = precision_score(all_labels, all_predictions, average='binary')\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test data: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "para_model_gpt_human(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e6bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4cf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cb29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60033bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
